## LangChain

[Chinese-LangChain æ‹†è§£ è®²è§£ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/623559601)

[sugarforever/LangChain-SQL-Chain (github.com)](https://github.com/sugarforever/LangChain-SQL-Chain)

## bloom

[BLOOM è®­ç»ƒèƒŒåçš„æŠ€æœ¯ (qq.com)](https://mp.weixin.qq.com/s/-q9opkoAomd9LZL9phm8bA)

[FreedomIntelligence/LLMZoo: âš¡LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.âš¡ (github.com)](https://github.com/FreedomIntelligence/LLMZoo)

## Alpaca

[tloen/alpaca-lora: Instruct-tune LLaMA on consumer hardware (github.com)](https://github.com/tloen/alpaca-lora)

https://github.com/LC1332/Chinese-alpaca-lora

## LLaMA

* [0é—¨æ§›å…‹éš†ChatGPTæ–¹æ¡ˆå†å‡çº§ï¼Œå¼€æºæ¨¡å‹å®Œæ•´å¤ç°ï¼Œåœ¨çº¿ä½“éªŒæ— éœ€æ³¨å†Œ (qq.com)](https://mp.weixin.qq.com/s/V5pCvYvkPXwiMw-FNIErXw)
* [hpcaitech/ColossalAI: Making large AI models cheaper, faster and more accessible (github.com)](https://github.com/hpcaitech/ColossalAI)
* [ymcui/Chinese-LLaMA-Alpaca: ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡å‹+æœ¬åœ°éƒ¨ç½² (Chinese LLaMA & Alpaca LLMs) (github.com)](https://github.com/ymcui/Chinese-LLaMA-Alpaca)
* [ä½¿ç”¨ Docker å’Œ Alpaca LoRA å¯¹ LLaMA 65B å¤§æ¨¡å‹è¿›è¡Œ Fine-Tune - è‹æ´‹åšå®¢ (soulteary.com)](https://soulteary.com/2023/03/25/model-finetuning-on-llama-65b-large-model-using-docker-and-alpaca-lora.html#å¯¹-llama-7b-å¤§æ¨¡å‹è¿›è¡Œ-fine-tune)
* [tloen/alpaca-lora: Instruct-tune LLaMA on consumer hardware (github.com)](https://github.com/tloen/alpaca-lora)
* [ã€å¼€æºGPTã€‘ä¸‰ä½åäººå°å“¥å¼€æºä¸­æ–‡è¯­è¨€æ¨¡å‹â€œéª†é©¼â€ï¼Œå•å¡å³å¯å®Œæˆè®­ç»ƒéƒ¨ç½²ï¼ŒèŠ±è´¹å‡ ç™¾è®­ç»ƒè‡ªå·±çš„ä¸­æ–‡èŠå¤©æ¨¡å‹ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/615968438)
* [ydli-ai/Chinese-ChatLLaMA: ä¸­æ–‡LLaMAåŸºç¡€æ¨¡å‹ï¼›ä¸­æ–‡ChatLLaMAå¯¹è¯æ¨¡å‹ï¼›é¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† (github.com)](https://github.com/ydli-ai/Chinese-ChatLLaMA)
* [LianjiaTech/BELLE: BELLE: BE Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼‰ (github.com)](https://github.com/LianjiaTech/BELLE)
* [3090å•å¡5å°æ—¶ï¼Œæ¯ä¸ªäººéƒ½èƒ½è®­ç»ƒä¸“å±ChatGPTï¼Œæ¸¯ç§‘å¤§å¼€æºLMFlow](https://zhuanlan.zhihu.com/p/620221835)
* [hpcaitech/ColossalAI: Making large AI models cheaper, faster and more accessible (github.com)](https://github.com/hpcaitech/ColossalAI)
* [å¼€å‘è€…ç¬‘ç–¯äº†ï¼ LLaMaæ³„éœ²å¼•çˆ†ChatGPTå¹³æ›¿ç‹‚æ½®ï¼Œå¼€æºLLMé¢†åŸŸå˜å¤© - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/620801077)
* [GPT fine-tuneå®æˆ˜ï¼š è®­ç»ƒæˆ‘è‡ªå·±çš„ ChatGPTğŸš€ğŸš€ğŸš€ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/616504594)
* [SCIR-HI/Huatuo-Llama-Med-Chinese: Repo for HuaTuo (åé©¼), Llama-7B tuned with Chinese medical knowledge. åé©¼æ¨¡å‹ä»“åº“ï¼ŒåŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„LLaMAæ¨¡å‹æŒ‡ä»¤å¾®è°ƒ (github.com)](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese)
* [FreedomIntelligence/LLMZoo: âš¡LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.âš¡ (github.com)](https://github.com/FreedomIntelligence/LLMZoo)
* [lm-sys/FastChat: The release repo for "Vicuna: An Open Chatbot Impressing GPT-4" (github.com)](https://github.com/lm-sys/FastChat)
* [LaWGPTï¼šåŸºäºä¸­æ–‡æ³•å¾‹çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹](https://github.com/pengxiao-song/LawGPT)

## chatGLM

* [visual-openllm/visual-openllm: something like visual-chatgpt, æ–‡å¿ƒä¸€è¨€çš„å¼€æºç‰ˆ (github.com)](https://github.com/visual-openllm/visual-openllm)
* [glm-finetuneåº”ç”¨-lich99/ChatGLM-finetune-LoRA: Code for fintune ChatGLM-6b using low-rank adaptation (LoRA) (github.com)](https://github.com/lich99/ChatGLM-finetune-LoRA)
* [mymusise/ChatGLM-Tuning: ä¸€ç§å¹³ä»·çš„chatgptå®ç°æ–¹æ¡ˆ, åŸºäºChatGLM-6B + LoRA (github.com)](https://github.com/mymusise/ChatGLM-Tuning)
* [!!!27182812/ChatGLM-chinese-insturct: æ¢ç´¢ä¸­æ–‡instructæ•°æ®åœ¨ChatGLM-6Bä¸Šå¾®è°ƒè¡¨ç° (github.com)](https://github.com/27182812/ChatGLM-chinese-insturct)
* [liangwq/Chatglm_lora_multi-gpu: chatglmå¤šgpuç”¨deepspeedå’Œ (github.com)](https://github.com/liangwq/Chatglm_lora_multi-gpu)
* [zero_nlp/simple_thu_chatglm6b at main Â· yuanzhoulvpi2017/zero_nlp (github.com)](https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/simple_thu_chatglm6b)
* [hikariming/alpaca_chinese_dataset: äººå·¥ç²¾è°ƒçš„ä¸­æ–‡å¯¹è¯æ•°æ®é›†å’Œä¸€æ®µchatglmçš„å¾®è°ƒä»£ç  (github.com)](https://github.com/hikariming/alpaca_chinese_dataset)
* [SCIR-HI/Med-ChatGLM: Repo for Chinese Medical ChatGLM åŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„ChatGLMæŒ‡ä»¤å¾®è°ƒ (github.com)](https://github.com/SCIR-HI/Med-ChatGLM)
* [thinksoso/ChatGLM-Instruct-Tuning: å¾®è°ƒChatGLM (github.com)](https://github.com/thinksoso/ChatGLM-Instruct-Tuning)
* [chatglm-maths](https://github.com/yongzhuo/chatglm-maths)
* [chatglmçš„å¾®è°ƒæœ‰æ²¡æœ‰ä¿å§†å¼çš„æ•™ç¨‹ï¼Ÿ?](https://www.zhihu.com/question/595670355)
* [hiyouga/ChatGLM-Efficient-Tuning: Fine-tuning ChatGLM-6B with PEFT | åŸºäº PEFT çš„é«˜æ•ˆ ChatGLM å¾®è°ƒ (github.com)](https://github.com/hiyouga/ChatGLM-Efficient-Tuning/tree/main)

## ä¸‹æ¸¸ä»»åŠ¡åº”ç”¨

* [gpt4IE](https://github.com/cocacola-lab/GPT4IE)
* [cocacola-lab/ChatIE: official repository for ChatIE paper and a tool of IE using ChatGPT. Note: we set a default openai key in the tool, you can tell us if reach limit. The response speed depends on the official openai chatgpt api. ( sometimes, the official is too crowded and the speed/model will be slow/overloaded.) (github.com)](https://github.com/cocacola-lab/ChatIE)
* [åŸºäºChatGPTçš„æƒ…æ„Ÿåˆ†æï¼Œåˆ†åˆ«å¯¹æ¯”äº†ç™¾åº¦å’Œchatgptçš„æ•ˆæœ]([taishan1994/ChatSA: åŸºäºChatGPTçš„æƒ…æ„Ÿåˆ†æ (github.com)](https://github.com/taishan1994/ChatSA))
* [visual-openllm/visual-openllm: something like visual-chatgpt, æ–‡å¿ƒä¸€è¨€çš„å¼€æºç‰ˆ (github.com)](https://github.com/visual-openllm/visual-openllm)
* [WangRongsheng/ChatGenTitle: ğŸŒŸ ChatGenTitleï¼šä½¿ç”¨ç™¾ä¸‡arXivè®ºæ–‡ä¿¡æ¯åœ¨LLaMAæ¨¡å‹ä¸Šè¿›è¡Œå¾®è°ƒçš„è®ºæ–‡é¢˜ç›®ç”Ÿæˆæ¨¡å‹ (github.com)](https://github.com/WangRongsheng/ChatGenTitle)
* [Moonvy/OpenPromptStudio: ğŸ¥£ AIGC æç¤ºè¯å¯è§†åŒ–ç¼–è¾‘å™¨ (github.com)](https://github.com/Moonvy/OpenPromptStudio)
* [Yidadaa/ChatGPT-Next-Web: One-Click to deploy well-designed ChatGPT web UI on Vercel. ä¸€é”®æ‹¥æœ‰ä½ è‡ªå·±çš„ ChatGPT ç½‘é¡µæœåŠ¡ã€‚ (github.com)](https://github.com/Yidadaa/ChatGPT-Next-Web)
* [yanqiangmiffy/InstructGLM: ChatGLM-6B æŒ‡ä»¤å­¦ä¹ |æŒ‡ä»¤æ•°æ®|Instruct (github.com)ï¼Œå¯ç›´æ¥ç”¨äºæ¨¡å‹è®­ç»ƒ](https://github.com/yanqiangmiffy/InstructGLM)
* [yuanjie-ai/ChatLLM: è½»æ¾ç©è½¬ LLM (github.com)](https://github.com/yuanjie-ai/ChatLLM)

## å…¶ä»–èµ„æº

* [nichtdax/awesome-totally-open-chatgpt: A list of totally open alternatives to ChatGPT (github.com)](https://github.com/nichtdax/awesome-totally-open-chatgpt)
* [ColossalChatï¼šå®Œæ•´RLHFå¹³æ›¿ChatGPTçš„å¼€æºæ–¹æ¡ˆ](https://zhuanlan.zhihu.com/p/618048558)
* [binary-husky/chatgpt_academic: ç§‘ç ”å·¥ä½œä¸“ç”¨ChatGPTæ‹“å±•ï¼Œç‰¹åˆ«ä¼˜åŒ–å­¦æœ¯Paperæ¶¦è‰²ä½“éªŒï¼Œæ”¯æŒè‡ªå®šä¹‰å¿«æ·æŒ‰é’®ï¼Œæ”¯æŒè‡ªå®šä¹‰å‡½æ•°æ’ä»¶ï¼Œæ”¯æŒmarkdownè¡¨æ ¼æ˜¾ç¤ºï¼ŒTexå…¬å¼åŒæ˜¾ç¤ºï¼Œä»£ç æ˜¾ç¤ºåŠŸèƒ½å®Œå–„ï¼Œæ–°å¢æœ¬åœ°Python/C++/Goé¡¹ç›®æ ‘å‰–æåŠŸèƒ½/é¡¹ç›®æºä»£ç è‡ªè¯‘è§£èƒ½åŠ›ï¼Œæ–°å¢PDFå’ŒWordæ–‡çŒ®æ‰¹é‡æ€»ç»“åŠŸèƒ½/PDFè®ºæ–‡å…¨æ–‡ç¿»è¯‘åŠŸèƒ½ (github.com)](https://github.com/binary-husky/chatgpt_academic)
* [microsoft/JARVIS: JARVIS, a system to connect LLMs with ML community. Paper: https://arxiv.org/pdf/2303.17580.pdf (github.com)](https://github.com/microsoft/JARVIS)
* [thinksoso/MedChat: çŸ¥è¯†æ£€ç´¢+ChatGPT (github.com)ï¼Œæ˜¯ä¸ªé€šç”¨webåº”ç”¨](https://github.com/thinksoso/MedChat)
* [acheong08/ChatGPT: Reverse engineered ChatGPT API (github.com)](https://github.com/acheong08/ChatGPT)
* [OpenLMLab/MOSS: An open-source tool-augmented conversational language model from Fudan University (github.com)](https://github.com/OpenLMLab/MOSS)
